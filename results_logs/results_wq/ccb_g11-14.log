PARTITION: Nvidia_A800
HOST: gpu[11-14]
GPU_NUM: 32
+ srun -p Nvidia_A800 -N 4 --ntasks-per-node 8 --gres=gpu:8 --mem 256G -K -w 'gpu[11-14]' ./scripts/executor.sh python coll_comm_bench.py --output './prof_data/coll_comm_bench_32_gpu[11-14].json'
srun: job 116526 queued and waiting for resources
srun: job 116526 has been allocated resources
[INFO]: Cluster init done !!!
COLL_COMM: allgather
msg_size: 16 MB, t_d: 1.0356 s, t_d/r: 0.3452, tput: 1.555 GB/s, busbw: 1.507 GB/s
msg_size: 64 MB, t_d: 3.5583 s, t_d/r: 1.1861, tput: 1.811 GB/s, busbw: 1.754 GB/s
msg_size: 256 MB, t_d: 12.3913 s, t_d/r: 4.1304, tput: 2.08 GB/s, busbw: 2.015 GB/s
msg_size: 1 GB, t_d: 63.1988 s, t_d/r: 21.0663, tput: 1.631 GB/s, busbw: 1.58 GB/s
COLL_COMM: reducescatter
msg_size: 16 MB, t_d: 0.7901 s, t_d/r: 0.2634, tput: 2.038 GB/s, busbw: 1.975 GB/s
msg_size: 64 MB, t_d: 4.7041 s, t_d/r: 1.568, tput: 1.37 GB/s, busbw: 1.327 GB/s
msg_size: 256 MB, t_d: 18.1123 s, t_d/r: 6.0374, tput: 1.423 GB/s, busbw: 1.378 GB/s
msg_size: 1 GB, t_d: 43.5444 s, t_d/r: 14.5148, tput: 2.367 GB/s, busbw: 2.293 GB/s
COLL_COMM: allreduce
msg_size: 16 MB, t_d: 1.6885 s, t_d/r: 0.5628, tput: 1.908 GB/s, busbw: 1.848 GB/s
msg_size: 64 MB, t_d: 5.368 s, t_d/r: 1.7893, tput: 2.4 GB/s, busbw: 2.325 GB/s
msg_size: 256 MB, t_d: 33.4067 s, t_d/r: 11.1356, tput: 1.543 GB/s, busbw: 1.495 GB/s
msg_size: 1 GB, t_d: 138.2689 s, t_d/r: 46.0896, tput: 1.491 GB/s, busbw: 1.444 GB/s
+ set +x
